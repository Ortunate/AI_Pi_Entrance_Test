{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ff094e",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "## 1. Env set up\n",
    "1. ... already set up\n",
    "2. pip install \n",
    "---\n",
    "## 2. Learning/Working route\n",
    "1. figure out task-involved knowledge range, in this case \n",
    "---\n",
    "## 3. Work Sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0608f",
   "metadata": {},
   "source": [
    "#### a. Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643f945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Net A:\n",
      "Output after first linear layer:\n",
      " [[-5 -3 -1  1  3]]\n",
      "Output after second linear layer:\n",
      " [[ 5.5  3.5  1.5 -0.5 -2.5]]\n",
      "\n",
      "Net B with Non-linearity:\n",
      "Output after first linear layer:\n",
      " [[-5 -3 -1  1  3]]\n",
      "Output after ReLU:\n",
      " [[0 0 0 1 3]]\n",
      "Output after second linear layer:\n",
      " [[ 0.5  0.5  0.5 -0.5 -2.5]]\n"
     ]
    }
   ],
   "source": [
    "# Subtask 1\n",
    "import numpy as np\n",
    "\n",
    "def linear_layer(x, w, b):\n",
    "    return np.dot(x, w) + b\n",
    "    \n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    对输入张量 x 执行元素级的 ReLU (Rectified Linear Unit) 操作。\n",
    "    公式为: f(x) = max(0, x)\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    将一个四维张量 (N, C, H, W) 展平为一个二维张量 (N, C*H*W)。\n",
    "    N 是批量大小，需要保持不变。\n",
    "    \"\"\"\n",
    "    # ===== 在此实现 =====\n",
    "    N = x.shape[0]\n",
    "    return x.reshape(N, -1)\n",
    "\n",
    "\n",
    "# comparison experiment\n",
    "x = np.array([[-2], [-1], [0], [1], [2]])\n",
    "w1, b1 = np.array([[2]]), np.array([-1])\n",
    "w2, b2 = np.array([[-1]]), np.array([0.5])\n",
    "\n",
    "# linear net A\n",
    "print(\"Linear Net A:\")\n",
    "out_a1 = linear_layer(x, w1, b1)\n",
    "out_a2 = linear_layer(out_a1, w2, b2)\n",
    "print(\"Output after first linear layer:\\n\", out_a1.T)\n",
    "print(\"Output after second linear layer:\\n\", out_a2.T)\n",
    "\n",
    "# net B with Non-linearity\n",
    "print(\"\\nNet B with Non-linearity:\")\n",
    "out_b1 = linear_layer(x, w1, b1)\n",
    "out_b2 = relu(out_b1)\n",
    "out_b3 = linear_layer(out_b2, w2, b2)\n",
    "print(\"Output after first linear layer:\\n\", out_b1.T)\n",
    "print(\"Output after ReLU:\\n\", out_b2.T)\n",
    "print(\"Output after second linear layer:\\n\", out_b3.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b24dd",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "(1)\n",
    "1. relu in this case changed all negative values to 0 and left positive values unchanged.\n",
    "2. original input is linearly distributed, and since net A is pure linear transformation, the output is also linearly distributed; while net B with relu breaks this linearity, making the output non-linearly distributed.\n",
    "\n",
    "(2)\n",
    "- Non-linear activation funcs are essential because however complex a linear func combination can be, it is still linear. Yet we need the model to learn and handle complex non-linear real-world data, which means non-linearity must be introduced, and this is why non-linear activation funcs matter.\n",
    "\n",
    "(3)\n",
    "- The flatten layer is used to convert multi-dimensional data into one-dimensional data, which is much easier to process(as a tensor). This can help to connect different types of layers, like between input layers and dense layers, CNN layers and dense layers, etc. Also we commonly use generators to convert low-dimensional data to high-dimensional data, which is like the opposite of flattening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794d09b",
   "metadata": {},
   "source": [
    "#### b. Subtask 2\n",
    "- Thinking:\n",
    "1. A fully connected layer needs 100\\*100\\*1(weights)+1(total bias) = 10001 parameters.\n",
    "2. a 3\\*3 kernel needs 9\\*1(weights)+1(bias) = 10 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26190ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for centered cross pattern:\n",
      " [[2. 2. 2.]\n",
      " [2. 5. 2.]\n",
      " [2. 2. 2.]]\n",
      "Output for shifted cross pattern:\n",
      " [[0. 0. 1.]\n",
      " [0. 2. 2.]\n",
      " [1. 2. 5.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv2d(x, w, b, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    x: input tensor in shape of (N, C_in, H_in, W_in)\n",
    "    w: weight tensor in shape of (C_out, C_in, H_k, W_k)\n",
    "    b: bias tensor in shape of (C_out,)\n",
    "    \"\"\"\n",
    "    N, C_in, H_in, W_in = x.shape\n",
    "    C_out, _, H_k, W_k = w.shape\n",
    "\n",
    "    H_out = (H_in + 2 * padding - H_k) // stride + 1\n",
    "    W_out = (W_in + 2 * padding - W_k) // stride + 1\n",
    "\n",
    "    if padding > 0:\n",
    "        x_padded = np.pad(x, ((0,0), (0,0), (padding,padding), \n",
    "                              (padding,padding)), mode='constant')\n",
    "    else:\n",
    "        x_padded = x\n",
    "        \n",
    "    out = np.zeros((N, C_out, H_out, W_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        for c_out in range(C_out):\n",
    "            for h_out in range(H_out):\n",
    "                for w_out in range(W_out):\n",
    "                    h_start = h_out * stride\n",
    "                    w_start = w_out * stride\n",
    "                    window = x_padded[n, :, h_start:h_start+H_k, w_start:w_start+W_k]\n",
    "                    \n",
    "                    conv_sum = np.sum(window * w[c_out, :, :, :])\n",
    "                    out[n, c_out, h_out, w_out] = conv_sum + b[c_out]\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #阶段一: 验证特征检测\n",
    "    # 1. 定义一个 5x5 的图像，中心有一个“十字”图案\n",
    "    image_centered = np.array([[\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ]], dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "\n",
    "    # 2. 设计一个 3x3 的卷积核，当它滑过输入图像时，如果它对应的图像区域与十字图案完全一致，它计算出的结果应该是最大的。\n",
    "    kernel_cross = np.array([[\n",
    "        [0, 1, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 1, 0]\n",
    "    ]], dtype=np.float32).reshape(1, 1, 3, 3)\n",
    "    bias_zero = np.array([0], dtype=np.float32)\n",
    "    \n",
    "    # 3. 执行卷积，观察输出\n",
    "    output_centered = conv2d(image_centered, kernel_cross, bias_zero, stride=1, padding=0)\n",
    "    print(\"Output for centered cross pattern:\\n\", output_centered[0, 0])\n",
    "\n",
    "\n",
    "    # 阶段二: 平移不变性\n",
    "    # 1. 创建一个新图像，将“十字”图案向右下方平移一格\n",
    "    image_centered = np.array([[\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 1, 1],\n",
    "        [0, 0, 0, 1, 0]\n",
    "    ]], dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "    # 2. 使用完全相同的卷积核进行卷积，并观察输出\n",
    "    \n",
    "    output_shifted = conv2d(image_centered, kernel_cross, bias_zero, stride=1, padding=0)\n",
    "    print(\"Output for shifted cross pattern:\\n\", output_shifted[0, 0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe867c",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "1. Locality: The convolution operation yields a feature map where each output value is influenced by a small, localized region of the input image. This is because the convolution kernel covers only a small part of the input at each iteration and computes a weighted sum and add a bias for that region. It has nothing to do with their absolute positions and other parts of the image.\n",
    "2. Translation Invariance: The convolution operation is translation invariant, because a translation of the feature(the cross's moving) in the input image will result in a corresponding translation of the feature(value '5.') in the output feature map, which is shown as the same value representing the same feature in different positions. It's just the same operation in another position.\n",
    "3. This means CNN can identify features effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b4ec0",
   "metadata": {},
   "source": [
    "#### c. Subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3270b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pooling Example:\n",
      "Original feature map 1:\n",
      " [[1. 2. 2. 0.]\n",
      " [4. 5. 3. 1.]\n",
      " [2. 3. 9. 9.]\n",
      " [0. 2. 9. 9.]]\n",
      "Original feature map 2:\n",
      " [[3. 2. 1. 4.]\n",
      " [2. 1. 3. 1.]\n",
      " [3. 9. 9. 1.]\n",
      " [1. 9. 9. 2.]]\n",
      "Pooled feature map 1:\n",
      " [[5. 3.]\n",
      " [3. 9.]]\n",
      "Pooled feature map 2:\n",
      " [[3. 4.]\n",
      " [9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "def max_pool2d(x, kernel_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    x: input tensor of shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "    N, C, H_in, W_in = x.shape\n",
    "    H_out = (H_in - kernel_size) // stride + 1\n",
    "    W_out = (W_in - kernel_size) // stride + 1\n",
    "\n",
    "    out = np.zeros((N, C, H_out, W_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for h_out in range(H_out):\n",
    "                for w_out in range(W_out):\n",
    "                    h_start = h_out * stride\n",
    "                    w_start = w_out * stride\n",
    "                    window = x[n, c, h_start:h_start+kernel_size, w_start:w_start+kernel_size]\n",
    "                    \n",
    "                    out[n, c, h_out, w_out] = np.max(window)\n",
    "    return out\n",
    "\n",
    "print(\"Max Pooling Example:\")\n",
    "# feature map with a simple pattern\n",
    "feature_map_1 = np.array([[\n",
    "    [1, 2, 2, 0],\n",
    "    [4, 5, 3, 1],\n",
    "    [2, 3, 9, 9],\n",
    "    [0, 2, 9, 9]\n",
    "]], dtype=np.float32).reshape(1, 1, 4, 4)\n",
    "\n",
    "feature_map_2 = np.array([[\n",
    "   [3, 2, 1, 4],\n",
    "   [2, 1, 3, 1],\n",
    "   [3, 9, 9, 1],\n",
    "   [1, 9, 9, 2],\n",
    "]], dtype=np.float32).reshape(1, 1, 4, 4)\n",
    "\n",
    "pooled_1 = max_pool2d(feature_map_1, kernel_size=2, stride=2)\n",
    "pooled_2 = max_pool2d(feature_map_2, kernel_size=2, stride=2)\n",
    "\n",
    "print(\"Original feature map 1:\\n\", feature_map_1[0, 0])\n",
    "print(\"Original feature map 2:\\n\", feature_map_2[0, 0])\n",
    "\n",
    "print(\"Pooled feature map 1:\\n\", pooled_1[0, 0])\n",
    "print(\"Pooled feature map 2:\\n\", pooled_2[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b03f3",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "- (1) we can see that the output feature map retains the most prominent features('9.') from the input feature map. The strongest feature is always retained after pooling, which means translation invariance is achieved to some extent: change the position of the feature won't change the feature value, so it still gets detected and retained.\n",
    "- (2) for this set up, the output of the pooling layer is halved in both height and width, effectively reducing the size of the feature map while retaining the most salient features. With a stride of s, the output dimensions will be reduced by a factor of s in both height and width, resulting a W*H/s^2 output feature map.\n",
    "- (3):\n",
    "    1. if adopting \"Average Pooling\", the output feature map will have averaged values in each pooling region, which may smooth out the features and make them less distinct. This could lead to loss of important details, especially if the features are not uniformly distributed.\n",
    "    2. when regarding feature selection, max pooling tends to effectively highlight the most prominent features, while average pooling may dilute them by averaging with less significant values. Just as their names suggest, \"max\" and \"average\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca0c15",
   "metadata": {},
   "source": [
    "#### d. Subtask 4\n",
    "##### Answer:\n",
    "- (1):\n",
    "    1. \n",
    "    2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a669b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape: (1, 1, 28, 28)\n",
      "Logits shape: (1, 10) Probs shape: (1, 10)\n",
      "\n",
      "Logits: [ 0.00223343 -0.00416911  0.00250573  0.00267944  0.00646766  0.0015071\n",
      " -0.00022611  0.0042225   0.00018825  0.01054704]\n",
      "Probs: [0.09996308 0.09932511 0.09999031 0.10000768 0.10038725 0.0998905\n",
      " 0.09971752 0.10016211 0.09975885 0.1007976 ]\n",
      "\n",
      "Checksum logits sum: 0.025955935726856137\n",
      "Checksum probs sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "# (在此之前应有已实现的 conv2d, relu, max_pool2d, flatten,linear_layer函数)\n",
    "# 固定随机种子，保证权重初始化一致\n",
    "np.random.seed(114514)\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    实现Softmax函数。\n",
    "    logits: input tensor of shape (N, num_classes)\n",
    "    \"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "# --- MNIST 数据集读取函数 ---\n",
    "def read_images(filename):\n",
    "    \"\"\"\n",
    "    读取MNIST图像文件\n",
    "    参数:\n",
    "      filename: MNIST图像文件路径\n",
    "    返回:\n",
    "      images: 图像数组列表\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        \n",
    "        image_data = array(\"B\", file.read())\n",
    "        \n",
    "    images = []\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(rows, cols)\n",
    "        images.append(img)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# =========================================================\n",
    "# ===== 任务：请根据下面的规约，在此处实现 TinyCNN_for_MNIST 类 =====\n",
    "# =========================================================\n",
    "#\n",
    "# --- 模型架构规约 ---\n",
    "# 1. 构造函数 `__init__(self)`:\n",
    "# 架构固定：Conv(1->4, k=3, stride=1, pad=1) -> ReLU -> MaxPool(2x2, s=2) -> Flatten -> Linear(->10 类)\n",
    "# 2. 前向传播方法 `forward(self, x)`:\n",
    "#    - 接收一个形状为 (N, 1, 28, 28) 的张量 x。\n",
    "#    - 按照以下顺序依次调用你实现的算子：\n",
    "#      Conv2d -> ReLU -> MaxPool2d -> Flatten -> Linear -> Softmax\n",
    "#    - 返回最终的 logits (Linear层输出) 和 probs (Softmax层输出)。\n",
    "\n",
    "class TinyCNN_for_MNIST:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.conv_w = np.random.randn(4, 1, 3, 3) * 0.01\n",
    "        self.conv_b = np.zeros(4)\n",
    "\n",
    "        self.lr_w = np.random.randn(784, 10) * 0.01\n",
    "        self.lr_b = np.zeros(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = conv2d(x, self.conv_w, self.conv_b,padding=1)\n",
    "        x = relu(x)\n",
    "        x = max_pool2d(x, 2, 2)\n",
    "        x = flatten(x)\n",
    "        logits = linear_layer(x, self.lr_w, self.lr_b)\n",
    "        probs = softmax(logits)\n",
    "        return logits, probs\n",
    "\n",
    "\n",
    "# --- 测试脚本 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 设置 MNIST 测试集文件路径\n",
    "    # !! 请将此路径修改为你自己的文件路径\n",
    "    mnist_test_file = '../mnist/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte'\n",
    "\n",
    "    if not os.path.exists(mnist_test_file):\n",
    "        print(f\"错误：找不到 MNIST 测试集文件 '{mnist_test_file}'\")\n",
    "    else:\n",
    "        # 2. 加载所有测试图像\n",
    "        test_images = read_images(mnist_test_file)\n",
    "        # 3. 选取第一张图像作为测试输入\n",
    "        first_test_image = test_images[0]\n",
    "        # 4. 预处理图像\n",
    "        input_tensor = (first_test_image.astype(np.float32) / 255.0 - 0.5) * 2.0\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=(0, 1))\n",
    "        # 5. 实例化模型并执行前向传播\n",
    "        model = TinyCNN_for_MNIST()\n",
    "        logits, probs = model.forward(input_tensor)\n",
    "\n",
    "        print(\"Input Tensor Shape:\", input_tensor.shape)\n",
    "        print(\"Logits shape:\", logits.shape, \"Probs shape:\", probs.shape)\n",
    "        np.set_printoptions(precision=8, suppress=False)\n",
    "        print(\"\\nLogits:\", logits[0])\n",
    "        print(\"Probs:\", probs[0])\n",
    "        print(\"\\nChecksum logits sum:\", float(np.sum(logits)))\n",
    "        print(\"Checksum probs sum:\", float(np.sum(probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe13a73",
   "metadata": {},
   "source": [
    "#### e. Subtask 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8c4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
