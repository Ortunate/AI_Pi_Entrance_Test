{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59825114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import base64\n",
    "import io\n",
    "import openai\n",
    "from openai import AsyncOpenAI\n",
    "from PIL import Image\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 0. Setup API Client and Environment ---\n",
    "# Using the API configuration from the task description\n",
    "print(\"Setting up Gemini API client...\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-yxhm7vIgkeffD0FU1bE5F797B654482d94CbB6DbBa556b96\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.ai-gaochao.cn/v1\"\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# --- 1. Prepare Data and Prompt ---\n",
    "# Reusing variables from Subtask 2\n",
    "# images_to_test: A list of 1010 PIL Image objects\n",
    "# true_labels: A list of 1010 integer labels\n",
    "# class_names: A list of 101 string class names\n",
    "\n",
    "# Helper function to convert PIL image to base64\n",
    "def pil_to_base64(image: Image.Image, format=\"jpeg\") -> str:\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Create a string of all possible class names for the prompt\n",
    "class_list_str = \", \".join(class_names)\n",
    "\n",
    "# Define the prompt template\n",
    "# This prompt guides the model to return only the class name for easy parsing.\n",
    "PROMPT_TEMPLATE = f\"\"\"\n",
    "You are an expert food classifier. Your task is to identify the food in the image and respond with ONLY the corresponding class name from the provided list. Do not add any extra text, explanations, or punctuation.\n",
    "\n",
    "Here are some examples of correct responses:\n",
    "- If you see a picture of a hamburger, you should respond with: hamburger\n",
    "- If you see a picture of sushi, you should respond with: sushi\n",
    "\n",
    "Now, identify the food in the following image.\n",
    "\n",
    "List of possible classes: {class_list_str}\n",
    "\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Data and prompt prepared. Will classify {len(images_to_test)} images.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Define Asynchronous API Call Function ---\n",
    "# MODIFICATION: Added a 'semaphore' argument\n",
    "async def classify_image_with_gemini(image: Image.Image, session_client: AsyncOpenAI, semaphore: asyncio.Semaphore):\n",
    "    # MODIFICATION: Acquire the semaphore before making the API call\n",
    "    async with semaphore:\n",
    "        base64_image = pil_to_base64(image)\n",
    "        \n",
    "        try:\n",
    "            response = await session_client.chat.completions.create(\n",
    "                model=\"gemini-2.5-flash\", # As specified in the task\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": PROMPT_TEMPLATE},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                            },\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=50, # A class name is short, so we don't need many tokens\n",
    "                temperature=0.0, # Set to 0 for deterministic, most likely output\n",
    "            )\n",
    "            # Extract the text and clean up any extra whitespace or quotes\n",
    "            return response.choices[0].message.content.strip().strip('\"')\n",
    "        except Exception as e:\n",
    "            # If an API call fails, return an error string\n",
    "            return f\"API_ERROR: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Run Asynchronous Classification ---\n",
    "async def run_classification():\n",
    "    print(\"\\nStarting classification with Gemini 2.5 Flash...\")\n",
    "    # MODIFICATION: Create a semaphore to limit concurrency to 50\n",
    "    concurrency_limit = 50\n",
    "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
    "    \n",
    "    # MODIFICATION: Pass the semaphore to each task\n",
    "    tasks = [classify_image_with_gemini(img, client, semaphore) for img in images_to_test]\n",
    "    \n",
    "    # tqdm_asyncio shows a progress bar for our async tasks\n",
    "    predictions = await tqdm_asyncio.gather(*tasks)\n",
    "    return predictions\n",
    "\n",
    "# Run the main async function\n",
    "# Note: This will make 1010 API calls and may take several minutes and incur costs.\n",
    "gemini_predictions_str = await run_classification()\n",
    "print(\"All API calls completed.\")\n",
    "\n",
    "# --- 4. Calculate Accuracy and Compare ---\n",
    "# Convert predicted string labels to integer IDs\n",
    "# Create a mapping from class name string to integer ID\n",
    "name_to_id_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "predicted_labels = []\n",
    "api_errors = 0\n",
    "invalid_responses = 0\n",
    "for pred_str in gemini_predictions_str:\n",
    "    if \"API_ERROR\" in pred_str:\n",
    "        api_errors += 1\n",
    "        predicted_labels.append(-1) # Mark as incorrect\n",
    "        continue\n",
    "\n",
    "    # Clean the model's output string\n",
    "    # 1. Convert to lowercase\n",
    "    # 2. Replace spaces and hyphens with underscores\n",
    "    # 3. Remove common punctuation and extra words\n",
    "    cleaned_str = pred_str.lower().replace(' ', '_').replace('-', '_')\n",
    "    \n",
    "    # Find the best matching class name in the cleaned string\n",
    "    found_match = False\n",
    "    for class_name in class_names:\n",
    "        if class_name in cleaned_str:\n",
    "            predicted_labels.append(name_to_id_map[class_name])\n",
    "            found_match = True\n",
    "            break # Stop after finding the first match\n",
    "    \n",
    "    if not found_match:\n",
    "        invalid_responses += 1\n",
    "        predicted_labels.append(-1) # Mark as incorrect if no class name is found\n",
    "# --- MODIFICATION END ---\n",
    "\n",
    "# Ensure lists are numpy arrays for metric calculation\n",
    "true_labels_np = np.array(true_labels)\n",
    "predicted_labels_np = np.array(predicted_labels)\n",
    "\n",
    "# Calculate Top-1 Accuracy\n",
    "gemini_accuracy = accuracy_score(true_labels_np, predicted_labels_np)\n",
    "\n",
    "print(\"\\n--- Subtask 5 Results ---\")\n",
    "print(f\"Total images processed: {len(images_to_test)}\")\n",
    "print(f\"Successful API calls: {len(images_to_test) - api_errors}\")\n",
    "print(f\"API errors: {api_errors}\")\n",
    "print(f\"Invalid/unrecognized responses: {invalid_responses}\")\n",
    "print(f\"\\nGemini 2.5 Flash Top-1 Accuracy: {gemini_accuracy:.4f}\")\n",
    "\n",
    "if 'top5_accuracy' in locals() or 'top5_accuracy' in globals():\n",
    "    print(f\"For comparison, SigLIP Zero-Shot Top-5 Accuracy (from Subtask 2): {top5_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"\\n(SigLIP Zero-Shot Top-5 Accuracy from Subtask 2 was not calculated in this session.)\")\n",
    "    \n",
    "print(\"\\nSubtask 5 Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
